version: '3.8'

services:
  # ============================================
  # Redis Service
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"  # üî• Ìò∏Ïä§Ìä∏ Ìè¨Ìä∏ Í∞úÎ∞© (localhost:6379Î°ú Ï†ëÍ∑º Í∞ÄÎä•)
    volumes:
      - redis-data:/data
    networks:
      - network
    command: >
      redis-server 
      --appendonly yes 
      --save 60 1000
      --maxmemory ${REDIS_MEMORY_LIMIT:-512M}
      --maxmemory-policy allkeys-lru
      --bind 0.0.0.0
      --protected-mode no
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${REDIS_MEMORY_LIMIT:-512M}
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ============================================
  # Parser Service
  # ============================================
  parser:
    build:
      context: ../Parser
      dockerfile: Dockerfile
    container_name: parser
    network_mode: "host"  # üî• Ìå®ÌÇ∑ Ï∫°Ï≤òÎ•º ÏúÑÌï¥ host ÎÑ§Ìä∏ÏõåÌÅ¨ ÌïÑÏöî
    privileged: true
    cap_add:
      - NET_ADMIN
      - NET_RAW
    environment:
      # ============================================
      # Redis Configuration
      # ============================================
      - REDIS_HOST=localhost  # üî• host ÎÑ§Ìä∏ÏõåÌÅ¨Ïù¥ÎØÄÎ°ú localhost
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_POOL_SIZE=${REDIS_POOL_SIZE:-8}
      - REDIS_ASYNC_WRITERS=${REDIS_ASYNC_WRITERS:-2}
      - REDIS_ASYNC_QUEUE_SIZE=${REDIS_ASYNC_QUEUE_SIZE:-10000}
      - REDIS_TIMEOUT_MS=${REDIS_TIMEOUT_MS:-1000}
      - REDIS_STREAM_MAX_LEN=${REDIS_STREAM_MAX_LEN:-100000}
      - REDIS_ASSET_CACHE_TTL=${REDIS_ASSET_CACHE_TTL:-3600}
      
      # ============================================
      # Elasticsearch Configuration (ÏõêÍ≤©)
      # ============================================
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST:-100.126.141.58}  # üî• Dashboard PC IP
      - ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT:-9200}
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      - ELASTICSEARCH_INDEX_PREFIX=${ELASTICSEARCH_INDEX_PREFIX:-ics-packets}
      - ELASTICSEARCH_USE_HTTPS=${ELASTICSEARCH_USE_HTTPS:-false}
      - ES_BULK_SIZE=${ES_BULK_SIZE:-100}
      - ES_BULK_FLUSH_INTERVAL_MS=${ES_BULK_FLUSH_INTERVAL_MS:-100}
      
      # ============================================
      # Parser Configuration
      # ============================================
      - NETWORK_INTERFACE=${NETWORK_INTERFACE:-veth1}
      - PARSER_MODE=${PARSER_MODE:-realtime}
      - BPF_FILTER=${BPF_FILTER:-}
      - OUTPUT_DIR=${OUTPUT_DIR:-/data/output}
      - ROLLING_INTERVAL=${ROLLING_INTERVAL:-0}
      - PARSER_THREADS=${PARSER_THREADS:-0}
      
      # ============================================
      # Logging
      # ============================================
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ../Parser/assets:/app/assets:ro
      - ./output:/data/output
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${PARSER_MEMORY_LIMIT:-2g}
          cpus: '${PARSER_CPU_LIMIT:-2.0}'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

networks:
  network:
    driver: bridge

volumes:
  redis-data:
    driver: local