version: '3.8'

services:
  # ============================================
  # Redis Service
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: ot-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - ot-network
    command: >
      redis-server
      --appendonly yes
      --save 60 1000
      --maxmemory 512M
      --maxmemory-policy allkeys-lru
      --bind 0.0.0.0
      --protected-mode no
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ============================================
  # Parser Service (Multi-stage build)
  # ============================================
  parser:
    build:
      context: ./Parser
      dockerfile: Dockerfile
      target: runtime
    container_name: ot-parser
    network_mode: "host"
    privileged: true
    cap_add:
      - NET_ADMIN
      - NET_RAW
    environment:
      # Redis Configuration (host network이므로 localhost)
      - REDIS_HOST=${REDIS_HOST:-localhost}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_POOL_SIZE=${REDIS_POOL_SIZE:-8}
      - REDIS_ASYNC_WRITERS=${REDIS_ASYNC_WRITERS:-2}
      - REDIS_ASYNC_QUEUE_SIZE=${REDIS_ASYNC_QUEUE_SIZE:-10000}
      - REDIS_TIMEOUT_MS=${REDIS_TIMEOUT_MS:-1000}

      # Elasticsearch Configuration (원격)
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST:-100.126.141.58}
      - ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT:-9200}
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      - ELASTICSEARCH_INDEX_PREFIX=${ELASTICSEARCH_INDEX_PREFIX:-ics-packets}
      - ELASTICSEARCH_USE_HTTPS=${ELASTICSEARCH_USE_HTTPS:-false}
      - ES_BULK_SIZE=${ES_BULK_SIZE:-100}
      - ES_BULK_FLUSH_INTERVAL_MS=${ES_BULK_FLUSH_INTERVAL_MS:-100}

      # Parser Configuration
      - NETWORK_INTERFACE=${NETWORK_INTERFACE:-any}
      - PARSER_MODE=${PARSER_MODE:-realtime}
      - BPF_FILTER=${BPF_FILTER:-}
      - OUTPUT_DIR=${OUTPUT_DIR:-/data/output}
      - ROLLING_INTERVAL=${ROLLING_INTERVAL:-0}
      - PARSER_THREADS=${PARSER_THREADS:-0}

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./Parser/assets:/app/assets:ro
      - ./output:/data/output
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${PARSER_MEMORY_LIMIT:-2g}
          cpus: '${PARSER_CPU_LIMIT:-2.0}'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

networks:
  ot-network:
    driver: bridge

volumes:
  redis-data:
    driver: local
